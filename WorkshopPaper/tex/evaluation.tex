\section{Evaluation}
We evaluate our approach by measuring reduction in the time and effort required to perform data preparation and data mining for the mode of transport prediction task. We use a two parameter evaluation strategy (time and accuracy) to provide us with summative data to show the impact of our approach. In the following sections we discuss our experiment setup, test user's skill level and the evaluation criteria used to summarize the assessment chart. 

\subsection{Experiment Setup}
In our experiment, we evaluated the steps using Microsoft Excel and Karma for processing the entire dataset. Three sets of the AccelerometerSensor and LocationProbe dataset were collected (one set for each day).  After each step, the time required for the user to perform the task was noted along with any system processing time. For certain tasks that involved programmatic computation like calculating DFT energy coefficient values for the acceleration data, or labeling the mode of transport for individual time ranges, we used Python scripts in both the approaches. Therefore, the time taken for writing these scripts and executing them was the same in both the approaches. Hence we excluded those timings in the evaluations. We had one user to perform all the tasks in the experiment. The proficiency level of the test user was advanced, i.e., the user was thorough in using Karma and Excel. 

In order to demonstrate our objective, we asked the user to perform two trials for processing the collected data set and noted their timings. The user first prepared the collected data from day one and generated an SVM model. Then he prepared the collected data from day two and tested the day-two data with the day-one model. Finally, the user prepared the collected data from day three and tested it with the SVM model built using the data from day one and day two. When using Karma, there were one-time setup tasks in which the user first modeled all of our services by adding semantic types to the service inputs. The user modeled the following data sources and services:
\begin{enumerate}
	\item \textit{Accelerometer sensor data}: To calculate the acceleration magnitude and extract the timestamp.
	\item \textit{Accelerometer data with DFT energy coefficients} â€“ The result of the addDFT service 
	\item \textit{LocationSensor data}: To model the speed, accuracy and timestamp columns
	\item \textit{AddDFT service}: Here we model the inputs for the addDFT service along with other meta data like service url, invocation method (GET or POST) etc.
	\item \textit{GetLabel service}: This service gets us the mode of transport for the given timestamp
	\item \textit{SVM Training}: This service model defines the SVM training and its inputs
	\item \textit{SVM Testing}: This service model defines the SVM testing and its inputs
\end{enumerate} 

Once the user had modeled all the services, he uploaded each file of the collected data and applied the semantic models. Karma automatically applied all the transformations defined in the models, so no manual effort was required. At the end of processing each file, the user invoked the SVM training and testing services. When Excel was used, the user did not need to setup the application. Table \ref{tab:excelProcessing} lists the user actions and time required to perform the task in Excel and Table \ref{tab:karmaProcessing} shows the timings when using Karma.

\subsection{Evaluation Criteria}
Our evaluation metric had two components -- efficiency and accuracy. The efficiency component included user interaction time and system processing time. The user interaction time was the time taken by the user to complete a task using the interface of the tool, for example publishing RDF in Karma or formatting column in Excel. The system processing time was the time taken by the tool to complete the computation and render the results after the user has issued the command. In terms of accuracy, we marked a data preparation task as correct if the user was able to process the data correctly and the resultant file could be used to invoke the SVM service.

\begin{table}[h]
	\centering
	\caption{Stepwise time chart for processing one file using Karma\label{tab:karmaProcessing}}
  	\begin{tabular}{ | >{\centering\arraybackslash}m{0.4cm} | >{\arraybackslash}m{3.6cm} | >{\centering\arraybackslash}m{0.6cm} | >{\centering\arraybackslash}m{1cm} | >{\centering\arraybackslash}m{0.8cm} | }
    	\hline
	    \textbf{Step} & \textbf{Task} & \textbf{User Time (sec)} & \textbf{System Processing Time (sec)} & \textbf{Total Elapsed Time} \\ \hline
	    1 & Modeling LocationProbe data & 34 & 18 & 0:52 \\ \hline
		2 & Publish RDF for LocationProbe & 12 & 6 & 1:10 \\ \hline
		3 & Modeling AccelerometerSensor data  & 18 & 5 & 1:34 \\ \hline
		4 & Publish RDF for AccelerometerSensor & 11 & 9 & 1:54 \\ \hline
		5 & Invoke addDFT service & 8 & 2 & 2:04 \\ \hline
		6 & Modeling DFT service output & 10 & 2 & 2:16 \\ \hline
		7 & Publish RDF for DFT output & 11 & 6 & 2:33 \\ \hline
		8 & Join with LocationProbe RDF & 12 & 5 & 2:50 \\ \hline
		9 & Publish the augmented model & 15 & 3 & 3:08 \\ \hline
		10 & Publish RDF for joined data & 10 & 6 & 3:24 \\ \hline
		11 & Invoke getLabel service & 8 & 2 & 3:34 \\ \hline
		12 & Filter our `NA' mode of transport & 31 & 3 & 4:08 \\ \hline
		12 & Model mode\_of\_transport data - the result of add label service & 6 & 3 & 4:17 \\ \hline
		13 & Publish RDF for Model of transport data & 20 & 4 & 4:41 \\ 
	    \hline
  	\end{tabular}
\end{table}

\subsection{Experiment Results}
Table \ref{tab:karmaProcessing} gives us the time taken for each of the data preparation tasks executed using Karma in one of the trials. The first step took the highest processing time because the combined location probe data file that was modeled, contained data from all of the three days. The transformations were executed for each step when the model was applied to this data set and since the number of rows was higher, it took more time to process. We observed that when a new worksheet is created in Karma, either by uploading a file or generated as a result of invoking a service, two steps were performed, namely applying a model and publishing the RDF. Together, these steps took roughly 20 to 25 seconds, depending upon the size of the dataset. After performing all the data transformations, RDF was published for the processed data using a new graph so that each data set can be individually used to invoke the SVM training and testing services. 

Table \ref{tab:excelProcessing} displays the time taken for the data preparation tasks executed using Excel. We can observe that the system processing time is very small when compared to Karma. This was because Excel is a native application and there is no communication latency between the interface and the application. We also observe that the user spends significant time switching between different application windows as well as the switching between the use of a mouse and keyboard. These switches were likely to introduce the most number of errors, which adds to the overall processing time. After processing the data for one day, it was stored in a new file to be used as training and testing sets for the SVM prediction task.

Table \ref{tab:timings} summarizes the timings for all of the trials. There are a number of observations that can be drawn from the table. When Karma was used, the user took the longest time to process the data set for the first day. As previously mentioned, the first iteration took more time to finish compared to the other trials since the LocationProbe data set was processed only once. However, when Excel was used, the data processing time for the first file was very close to the avarage time taken by Excel. Since most of the processing was automated in Karma, the user was relieved from repeating the commands. The time taken to invoke the SVM services for training and testing remained consistent throughout both the approaches. The Karma setup time was calculated only once as it was a one-time process. The user was also not expected to get a better result or a faster time. 

\begin{table}[h]
	\centering
	\caption{Stepwise time chart for processing one file using Excel\label{tab:excelProcessing}}
  	\begin{tabular}{ | >{\centering\arraybackslash}m{0.4cm} | >{\arraybackslash}m{3.6cm} | >{\centering\arraybackslash}m{0.6cm} | >{\centering\arraybackslash}m{1cm} | >{\centering\arraybackslash}m{0.8cm} | }
    	\hline
	    \textbf{Step} & \textbf{Task} & \textbf{User Time (sec)} & \textbf{System Processing Time (sec)} & \textbf{Total Elapsed Time} \\ \hline
	    1 & Process AccelerometerSensor data --- add magnitude and set timestamp column to be 4 decimal places & 44 & 0 & 0:44 \\ \hline
		2 & Extract timestamp and Magnitude in new worksheet and save as CSV & 41 & 0 & 1:25 \\ \hline
		3 & Invoke addDFT script & 8 & 2 & 1:35 \\ \hline
		4 & Process addDFT output file --- format timestamp column to be 4 decimal places & 12 & 0 & 1:48 \\ \hline
		5 & Copy timestamp, speed and accuracy columns from LocationProbe data into a new worksheet & 41 & 0 & 2:29 \\ \hline
		6 & Process timestamp column to be 4 decimal places, and add a new column to round off the decimal & 25 & 0 & 2:54 \\ \hline
		7 & Add vLookUp formulae in the AccelerometerData worksheet for Speed & 27 & 0 & 3:21 \\ \hline
		8 & Add vLookUp formulae in the AccelerometerData worksheet for Accuracy & 34 & 0 & 3:55 \\ \hline
		9 & Apply filter to remove unmatched --- NA rows after join and delete them. & 43 & 0 & 4:38 \\ \hline
		10 & Save this accelerometer with DFT data for input to labeling service & 19 & 0 & 4:57 \\ \hline
		11 & Invoke the labeling service over the exported CSV file  & 12 & 1 & 5:09 \\ \hline
		12 & Filter data to remove NA columns & 32 & 0 & 5:41 \\ \hline
		13 & Save the file as ProcessedData file & 6 & 0 & 5:48 \\ \hline
		14 & Copy the ProcessedData file to the required location for SVM invocation & 10 & 0 & 5:58 \\
	    \hline
  	\end{tabular}  	
\end{table}

\begin{table*}[ht!]
	\centering
	\caption{Timing summary\label{tab:timings}}
	\begin{tabular}{c|c|c|c|c|c|c|c|}
	\hline
	\multicolumn{1}{ |c }{\multirow{8}{*}{Trial 1} } &
	\multicolumn{1}{ |c| }{} & \multicolumn{3}{ c| }{Karma} & \multicolumn{3}{ c| }{Excel} \\ \cline{3-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |c| }{} & Time & TotalSeconds & Accuracy & Time & TotalSeconds & Accuracy \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Dataset 1} & 4:41 min & 281 & Correct & 5:58 min & 358 & Correct     \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM training} & 0:12 min & 12 & Correct & 0:35 min & 35 & Correct   \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Dataset 2} & 3:20 min & 200 & Correct & 5:50 min & 350 & Correct  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM testing on dataset2} & 0:14 min & 14 & Correct & 0:30 min & 30 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM training using dat set 1 and 2 combined} & 0:29 min & 29 & Correct & 1:20 min & 80 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Dataset 3} & 3:13 min & 193 & Correct & 5:43 min & 343 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM testing on dataset3} & 0:12 min & 12 & Correct & 0:29 min & 29 & Correct \\ \cline{1-8}

	\multicolumn{1}{ |p{0.8cm} }{\multirow{8}{*}{Trial 2} } & \multicolumn{1}{ |l| }{Dataset 1} & 3:18 min & 198 & Correct & 5:36 min & 326 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM training} & 0:11 min & 11 & Correct & 0:31 min & 31 & Correct   \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Dataset 2} & 2:49 min & 169 & Correct & 5:25 min & 325 & Correct  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM testing on dataset2} & 0:16 min & 16 & Correct & 0:28 min & 28 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM training using dat set 1 and 2 combined} & 0:25 min & 25 & Correct & 1:43 min & 103 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Dataset 3} & 3:05 min & 185 & Correct & 5:53 min & 353 & Correct \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{1}{ |l| }{Invoke SVM testing on dataset3} & 0:14 min & 14 & Correct & 0:29 min & 29 & Correct \\ \cline{1-8}

	\multicolumn{1}{ |p{0.8cm} }{\multirow{4}{*}{Analysis} } & \multicolumn{1}{ |l| }{Total} & 22:39 min & 1359 &  & 40:20 min & 2420 &  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{4}{ |l| }{Total Reduction excluding karma setup} & \multicolumn{2}{ l| }{17:41 min} & 42.14\%  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{4}{ |l| }{Total Reduction including karma setup (+9:30 min)} & \multicolumn{2}{ l| }{8:11 min} & 20.28\%  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{6}{ |l| }{Accuracy with Karma} & 100.00\%  \\ \cline{2-8}
	\multicolumn{1}{ |c  }{}  & \multicolumn{6}{ |l| }{Accuracy with Excel} & 100.00\%  \\ \cline{1-8}
	\end{tabular}	
\end{table*}

The accuracy for our experiment is the number of data preparation tasks completed correctly. We evaluated the correctness of the task as discrete Boolean values. At the end of processing a data file, if we were able to invoke the SVM training or testing service with no errors, we marked it as a successful completion. In our experiment, having 100\% accuracy at the end of all the trials for Excel and Karma does not indicate that the task is easy to perform, but it highlights the reliability and availability of using Karma to replay the transformations any number of times and always yield correct results. When using Excel, the user can always undo a certain transformation if there is an error and rectify it. Hence it yields 100\% while using Excel.

Both the trials showed that there was not much variation in invoking the SVM services after processing the files. The difference was in the ability to replay the steps in Karma. Every time we pick a new file to process, Karma took approximately one minute less than Excel. It took 9:30 minutes to complete the Karma setup while the execution phase took a total of 22:39 minutes to complete two trials of data preparation and mining. On the other hand, the Excel execution phase took 40:20 minutes to complete the two trials. We initially compare Karma's execution time with the total time taken for Excel since both involve repetition all of the tasks for every file. We observed a 42.14\% reduction in time taken for this iterative process by using Karma to process six data files. When we include the setup time for Karma, we observed a 20.28\% improvement in the time for the same number of files. Therefore, in our experiment, Karma requires 4 iterations of data processing to amortize the cost of its setup. 

To emphasize the potential of our results, we could extrapolate our dataset to have 100 days of mode of transportation data. Then the time spent in preparing the data using Excel could be approximately 670 minutes. However the process could be completed in approximately 387 minutes using Karma, which also included the setup time. When we processed 6 files, Karma's setup time caused the time reduction to decrease from 42.14\% to 20.28\%. But when we processed 100 files, the reduction ratio is more or less the same even if the Karma setup time is included or excluded. 

We also discuss another important scenario where multiple users of the same skill level are involved in our experiment to process the data. For example, we will consider 10 users participating in our experiment. If every user is using Karma individually, they will all roughly need 9:30 minutes to setup Karma and 22:39 minutes to process the files. A total of 5.3 person hours is spent in data preparation. Here the real benefit of modeling data source and services to an ontology using Karma, is the ability to share models across users. Therefore, if one user spent his 9:30 minutes in setting up Karma and shares the models with all the other users, the data preparation task is completed in 3.7 hours, saving 26\% of the time that was required previously. Based on the observations, we can conclude that Karma improves efficiency in data preparation and data mining on large data sets by reducing time taken and manual efforts.